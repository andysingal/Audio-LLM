{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98348c7b-b514-4c6c-bf4a-cdfb19853a98",
   "metadata": {
    "collapsed": false,
    "name": "INTRODUCTION"
   },
   "source": [
    "# Getting Started with üé§ Audio Sentiment Analysis using Snowflake Notebooks üìä\n",
    "\n",
    "Transform audio files into actionable insights by analyzing emotional tone and sentiment using Snowflake Notebooks! ‚ö°Ô∏è\n",
    "\n",
    "This notebook demonstrates how to build an end-to-end application that:\n",
    "1. Processes audio files using PyTorch and Hugging Face pipelines\n",
    "2. Extracts emotional tone and transcripts from audio\n",
    "3. Performs sentiment analysis on transcribed text\n",
    "4. Compares emotional tone with sentiment scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3216ac67-4576-4e12-9eaa-2c6adbad6918",
   "metadata": {
    "collapsed": false,
    "name": "INSTALL_PACKAGES_MD"
   },
   "source": [
    "## Setting Up Your Environment üéí\n",
    "\n",
    "First, we'll install required packages\n",
    "- `torch`: For deep learning and neural network operations\n",
    "- `librosa`: For loading and manipulating audio files\n",
    "- `transformers`: For accessing pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d6e35-5eed-4f60-8627-e836ba8f3df8",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "INSTALL_PACKAGES",
    "resultHeight": 1275
   },
   "outputs": [],
   "source": [
    "!pip install librosa transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32971f8-b164-4d5b-8613-41eaaa324164",
   "metadata": {
    "collapsed": false,
    "name": "ENV_MD"
   },
   "source": [
    "## Configuring the Environment üîß\n",
    "\n",
    "Import required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "ENV_CONFIGURATION",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import pipeline\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.cortex import Sentiment \n",
    "\n",
    "session = get_active_session()\n",
    "stage_name = 'audio_files'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7948b2c-a7f1-4c9d-adfe-576fcb36796a",
   "metadata": {
    "collapsed": false,
    "name": "PROCESSING_FILES_MD"
   },
   "source": [
    "## Processing Audio Files üéß\n",
    "\n",
    "The main processing function:\n",
    "1. Loads audio files from Snowflake stage\n",
    "2. Analyzes emotional tone using wav2vec2 model\n",
    "3. Transcribes audio using Whisper model\n",
    "4. Performs sentiment analysis on transcripts\n",
    "5. Compares emotional tone with sentiment scores\n",
    "\n",
    "Key components:\n",
    "- Audio classification pipeline using for learning tonality `ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition`\n",
    "- Speach to text with `whisper`\n",
    "- Sentiment analysis using `Snowflake Cortex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a44db-88af-4151-9bdf-9b49ae69eccf",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "PROCESS_FILES"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # for multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "#For consistent output for quickstart\n",
    "set_seed(1280)\n",
    "\n",
    "# Create empty lists to store the results\n",
    "results = []\n",
    "\n",
    "# Initialize both pipelines\n",
    "audio_pipeline = pipeline(\"audio-classification\", model=\"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\", device=device)\n",
    "whisper_pipeline = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base\", device=device)\n",
    "\n",
    "files = session.sql(f\"LIST @{stage_name}\").collect()\n",
    "file_names = [file['name'].split('/')[-1] for file in files]\n",
    "\n",
    "for file_name in file_names:\n",
    "    session.file.get(f'@{stage_name}/{file_name}', \"downloads/\")\n",
    "    audio, rate = librosa.load(f'downloads/{file_name}', sr=16000, mono=True)\n",
    "    \n",
    "    # Get emotional tone\n",
    "    result = audio_pipeline(audio)\n",
    "    emotion = sorted(result, key=lambda x: x['score'], reverse=True)[0]\n",
    "    \n",
    "    # Get transcript and sentiment\n",
    "    transcript = whisper_pipeline(audio)\n",
    "    sentiment_score = Sentiment(transcript['text'])\n",
    "    \n",
    "    # Determine if emotion and sentiment match\n",
    "    match = \"Unknown\"\n",
    "    if emotion['label'] == \"angry\":\n",
    "        match = \"Match\" if sentiment_score < 0 else \"Do Not Match\"\n",
    "    elif emotion['label'] == \"happy\":\n",
    "        match = \"Match\" if sentiment_score > 0 else \"Do Not Match\"\n",
    "    \n",
    "    # Store results in dictionary\n",
    "    results.append({\n",
    "        'File': file_name,\n",
    "        'Emotion': emotion['label'],\n",
    "        'Emotion_Score': round(emotion['score'], 3),\n",
    "        'Transcript': transcript['text'],\n",
    "        'Sentiment_Score': sentiment_score,\n",
    "        'Tone_Sentiment_Match': match\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "james.cha-earley@snowflake.com",
   "authorId": "3919642301233",
   "authorName": "JAMESE",
   "lastEditTime": 1737663392963,
   "notebookId": "7puhi5kloqygumordneu",
   "sessionId": "87593c5b-0821-4a94-b633-ab53c637afe1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
